{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "04ac14935f6ed29b3349ee8f41114d2dfa2ba78ce87cf701ad9b7ca15955b787"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is largely based on the tutorials at: https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "model_settings = {'epochs': 100, 'batch_size': 4, 'train_test_ratio': 0.7, 'hidden_layers': 3, 'units': 100, 'start_date': '2020-01-01', 'n_steps_in': 60, 'n_steps_out': 30, 'symbol': 'CTXR'}\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "stock_symbol     ABEO    ABIO    ABMC     ABMT  ...   ZIVO     ZOM    ZSAN    ZYNE\n",
       "price_datetime                                  ...                               \n",
       "2020-01-02      3.210  5.6800  0.0700  0.10000  ...  0.160  0.3310  1.5200  5.8800\n",
       "2020-01-03      2.900  5.5600  0.0700  0.10000  ...  0.160  0.3320  1.5500  5.8100\n",
       "2020-01-06      2.770  5.6300  0.0700  0.10000  ...  0.160  0.3130  1.6400  5.7000\n",
       "2020-01-07      2.570  5.6700  0.0800  0.10000  ...  0.160  0.3130  1.7100  5.5600\n",
       "2020-01-08      2.620  6.0700  0.0800  0.10000  ...  0.160  0.3200  1.6200  5.3100\n",
       "...               ...     ...     ...      ...  ...    ...     ...     ...     ...\n",
       "2021-06-01      1.710  3.4900  0.0636  0.07920  ...  4.255  0.8239  0.8025  5.0700\n",
       "2021-06-02      1.745  3.5690  0.0645  0.11490  ...  4.145  0.8379  0.8006  5.2800\n",
       "2021-06-03      1.825  3.7000  0.0631  0.07609  ...  4.290  1.0050  0.8069  5.1819\n",
       "2021-06-04      1.705  3.6451  0.0620  0.08000  ...  4.350  0.9110  0.8187  5.1800\n",
       "2021-06-07      1.740  3.6400  0.0735  0.06650  ...  4.250  0.9667  0.9148  5.3100\n",
       "\n",
       "[360 rows x 412 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>stock_symbol</th>\n      <th>ABEO</th>\n      <th>ABIO</th>\n      <th>ABMC</th>\n      <th>ABMT</th>\n      <th>ABUS</th>\n      <th>ACER</th>\n      <th>ACHFF</th>\n      <th>ACRX</th>\n      <th>ACST</th>\n      <th>ACUR</th>\n      <th>ADIL</th>\n      <th>ADMA</th>\n      <th>ADMP</th>\n      <th>ADMS</th>\n      <th>ADMT</th>\n      <th>ADXS</th>\n      <th>AEMD</th>\n      <th>AEZS</th>\n      <th>AGE</th>\n      <th>AGEN</th>\n      <th>AGRX</th>\n      <th>AGTC</th>\n      <th>AHPI</th>\n      <th>AIKI</th>\n      <th>AIM</th>\n      <th>AKBA</th>\n      <th>AKTX</th>\n      <th>ALEAF</th>\n      <th>ALID</th>\n      <th>ALIM</th>\n      <th>ALNA</th>\n      <th>ALRN</th>\n      <th>AMPE</th>\n      <th>AMRN</th>\n      <th>AMRX</th>\n      <th>AMS</th>\n      <th>ANIX</th>\n      <th>APEN</th>\n      <th>APM</th>\n      <th>APOP</th>\n      <th>...</th>\n      <th>TRTC</th>\n      <th>TRVI</th>\n      <th>TRVN</th>\n      <th>TTNP</th>\n      <th>TTOO</th>\n      <th>TXMD</th>\n      <th>TYHT</th>\n      <th>TYME</th>\n      <th>VBIO</th>\n      <th>VBIV</th>\n      <th>VBLT</th>\n      <th>VCNX</th>\n      <th>VEGGF</th>\n      <th>VERO</th>\n      <th>VEXTF</th>\n      <th>VIVE</th>\n      <th>VIVXF</th>\n      <th>VLNCF</th>\n      <th>VNRX</th>\n      <th>VRAY</th>\n      <th>VSTM</th>\n      <th>VTGN</th>\n      <th>VTVT</th>\n      <th>VVCIF</th>\n      <th>WDDMF</th>\n      <th>WKULF</th>\n      <th>WORX</th>\n      <th>XBIO</th>\n      <th>XCUR</th>\n      <th>XERS</th>\n      <th>XPHYF</th>\n      <th>XTLB</th>\n      <th>XTNT</th>\n      <th>XXII</th>\n      <th>YCBD</th>\n      <th>ZIOP</th>\n      <th>ZIVO</th>\n      <th>ZOM</th>\n      <th>ZSAN</th>\n      <th>ZYNE</th>\n    </tr>\n    <tr>\n      <th>price_datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-02</th>\n      <td>3.210</td>\n      <td>5.6800</td>\n      <td>0.0700</td>\n      <td>0.10000</td>\n      <td>2.94</td>\n      <td>3.790</td>\n      <td>0.7410</td>\n      <td>2.070</td>\n      <td>2.3800</td>\n      <td>0.280</td>\n      <td>2.4400</td>\n      <td>3.935</td>\n      <td>0.7500</td>\n      <td>4.080</td>\n      <td>0.190</td>\n      <td>1.0900</td>\n      <td>1.2500</td>\n      <td>0.8800</td>\n      <td>1.9500</td>\n      <td>4.040</td>\n      <td>2.9700</td>\n      <td>4.15</td>\n      <td>1.26</td>\n      <td>1.4000</td>\n      <td>0.6100</td>\n      <td>6.340</td>\n      <td>1.740</td>\n      <td>0.4750</td>\n      <td>1.55</td>\n      <td>8.160</td>\n      <td>2.8900</td>\n      <td>0.595</td>\n      <td>0.5900</td>\n      <td>21.530001</td>\n      <td>4.7700</td>\n      <td>2.5500</td>\n      <td>3.000</td>\n      <td>2.9200</td>\n      <td>13.6600</td>\n      <td>2.390</td>\n      <td>...</td>\n      <td>0.17000</td>\n      <td>3.750</td>\n      <td>0.858</td>\n      <td>6.6000</td>\n      <td>1.160</td>\n      <td>2.440</td>\n      <td>5.6250</td>\n      <td>1.4200</td>\n      <td>0.050</td>\n      <td>1.3400</td>\n      <td>1.2500</td>\n      <td>5.01</td>\n      <td>0.15180</td>\n      <td>4.550</td>\n      <td>0.55930</td>\n      <td>11.0000</td>\n      <td>0.4316</td>\n      <td>2.73000</td>\n      <td>4.670</td>\n      <td>4.055</td>\n      <td>1.330</td>\n      <td>0.7500</td>\n      <td>1.775</td>\n      <td>0.16200</td>\n      <td>0.6743</td>\n      <td>0.21000</td>\n      <td>2.921</td>\n      <td>1.4000</td>\n      <td>2.800</td>\n      <td>6.70</td>\n      <td>0.75</td>\n      <td>1.3000</td>\n      <td>1.580</td>\n      <td>1.140</td>\n      <td>2.3400</td>\n      <td>4.6200</td>\n      <td>0.160</td>\n      <td>0.3310</td>\n      <td>1.5200</td>\n      <td>5.8800</td>\n    </tr>\n    <tr>\n      <th>2020-01-03</th>\n      <td>2.900</td>\n      <td>5.5600</td>\n      <td>0.0700</td>\n      <td>0.10000</td>\n      <td>3.08</td>\n      <td>3.580</td>\n      <td>0.7410</td>\n      <td>2.040</td>\n      <td>2.3300</td>\n      <td>0.280</td>\n      <td>2.4400</td>\n      <td>3.760</td>\n      <td>0.8400</td>\n      <td>4.100</td>\n      <td>0.200</td>\n      <td>1.1200</td>\n      <td>1.1500</td>\n      <td>0.8800</td>\n      <td>1.9000</td>\n      <td>3.860</td>\n      <td>2.9000</td>\n      <td>4.18</td>\n      <td>1.24</td>\n      <td>1.3200</td>\n      <td>0.5600</td>\n      <td>6.400</td>\n      <td>1.710</td>\n      <td>0.4640</td>\n      <td>1.55</td>\n      <td>7.590</td>\n      <td>2.7800</td>\n      <td>0.605</td>\n      <td>0.6000</td>\n      <td>20.950001</td>\n      <td>4.7200</td>\n      <td>2.4300</td>\n      <td>3.160</td>\n      <td>2.8600</td>\n      <td>14.7300</td>\n      <td>2.475</td>\n      <td>...</td>\n      <td>0.17000</td>\n      <td>4.284</td>\n      <td>0.859</td>\n      <td>7.8000</td>\n      <td>1.230</td>\n      <td>2.310</td>\n      <td>5.4900</td>\n      <td>1.3900</td>\n      <td>0.050</td>\n      <td>1.3200</td>\n      <td>1.2600</td>\n      <td>4.94</td>\n      <td>0.15500</td>\n      <td>4.480</td>\n      <td>0.55216</td>\n      <td>10.1000</td>\n      <td>0.4400</td>\n      <td>2.78000</td>\n      <td>4.800</td>\n      <td>4.010</td>\n      <td>1.300</td>\n      <td>0.7300</td>\n      <td>1.830</td>\n      <td>0.15800</td>\n      <td>0.6516</td>\n      <td>0.19375</td>\n      <td>2.900</td>\n      <td>1.4600</td>\n      <td>2.830</td>\n      <td>6.07</td>\n      <td>0.75</td>\n      <td>1.4100</td>\n      <td>1.530</td>\n      <td>1.090</td>\n      <td>2.2700</td>\n      <td>4.5000</td>\n      <td>0.160</td>\n      <td>0.3320</td>\n      <td>1.5500</td>\n      <td>5.8100</td>\n    </tr>\n    <tr>\n      <th>2020-01-06</th>\n      <td>2.770</td>\n      <td>5.6300</td>\n      <td>0.0700</td>\n      <td>0.10000</td>\n      <td>3.18</td>\n      <td>3.690</td>\n      <td>0.7410</td>\n      <td>2.010</td>\n      <td>2.2100</td>\n      <td>0.280</td>\n      <td>2.4200</td>\n      <td>3.670</td>\n      <td>0.8900</td>\n      <td>4.140</td>\n      <td>0.190</td>\n      <td>1.0700</td>\n      <td>1.1200</td>\n      <td>0.9200</td>\n      <td>1.7800</td>\n      <td>3.780</td>\n      <td>2.8500</td>\n      <td>4.13</td>\n      <td>1.25</td>\n      <td>1.3000</td>\n      <td>0.5600</td>\n      <td>6.620</td>\n      <td>1.700</td>\n      <td>0.4440</td>\n      <td>1.55</td>\n      <td>7.760</td>\n      <td>2.7000</td>\n      <td>0.649</td>\n      <td>0.6900</td>\n      <td>21.230000</td>\n      <td>4.7300</td>\n      <td>2.5300</td>\n      <td>3.160</td>\n      <td>2.9000</td>\n      <td>14.7500</td>\n      <td>2.410</td>\n      <td>...</td>\n      <td>0.16000</td>\n      <td>4.372</td>\n      <td>0.861</td>\n      <td>9.0000</td>\n      <td>1.190</td>\n      <td>2.340</td>\n      <td>5.9400</td>\n      <td>1.5400</td>\n      <td>0.050</td>\n      <td>1.4200</td>\n      <td>1.2500</td>\n      <td>4.99</td>\n      <td>0.19800</td>\n      <td>4.600</td>\n      <td>0.56000</td>\n      <td>10.1000</td>\n      <td>0.4474</td>\n      <td>2.65000</td>\n      <td>5.160</td>\n      <td>3.880</td>\n      <td>1.310</td>\n      <td>0.7300</td>\n      <td>1.890</td>\n      <td>0.16900</td>\n      <td>0.6249</td>\n      <td>0.21625</td>\n      <td>2.920</td>\n      <td>1.5200</td>\n      <td>2.860</td>\n      <td>5.79</td>\n      <td>0.75</td>\n      <td>1.4200</td>\n      <td>1.550</td>\n      <td>1.100</td>\n      <td>2.2200</td>\n      <td>4.4900</td>\n      <td>0.160</td>\n      <td>0.3130</td>\n      <td>1.6400</td>\n      <td>5.7000</td>\n    </tr>\n    <tr>\n      <th>2020-01-07</th>\n      <td>2.570</td>\n      <td>5.6700</td>\n      <td>0.0800</td>\n      <td>0.10000</td>\n      <td>3.04</td>\n      <td>3.710</td>\n      <td>0.7250</td>\n      <td>2.070</td>\n      <td>2.3300</td>\n      <td>0.240</td>\n      <td>2.3900</td>\n      <td>3.760</td>\n      <td>0.8200</td>\n      <td>4.160</td>\n      <td>0.180</td>\n      <td>1.3000</td>\n      <td>1.1500</td>\n      <td>0.9700</td>\n      <td>1.8000</td>\n      <td>3.710</td>\n      <td>2.8500</td>\n      <td>4.27</td>\n      <td>1.27</td>\n      <td>1.3300</td>\n      <td>0.6800</td>\n      <td>6.820</td>\n      <td>1.740</td>\n      <td>0.4400</td>\n      <td>1.55</td>\n      <td>6.677</td>\n      <td>2.5700</td>\n      <td>0.650</td>\n      <td>0.7300</td>\n      <td>20.080000</td>\n      <td>4.6800</td>\n      <td>2.4000</td>\n      <td>2.970</td>\n      <td>2.8000</td>\n      <td>14.8100</td>\n      <td>4.090</td>\n      <td>...</td>\n      <td>0.16000</td>\n      <td>4.376</td>\n      <td>0.880</td>\n      <td>7.2000</td>\n      <td>1.190</td>\n      <td>2.260</td>\n      <td>5.5530</td>\n      <td>1.7500</td>\n      <td>0.050</td>\n      <td>1.3900</td>\n      <td>1.2500</td>\n      <td>4.90</td>\n      <td>0.21700</td>\n      <td>5.390</td>\n      <td>0.62680</td>\n      <td>10.5000</td>\n      <td>0.4400</td>\n      <td>2.50335</td>\n      <td>4.910</td>\n      <td>3.760</td>\n      <td>1.260</td>\n      <td>0.7200</td>\n      <td>1.770</td>\n      <td>0.16700</td>\n      <td>0.6100</td>\n      <td>0.25875</td>\n      <td>3.100</td>\n      <td>1.4700</td>\n      <td>2.800</td>\n      <td>6.39</td>\n      <td>0.75</td>\n      <td>1.4100</td>\n      <td>1.590</td>\n      <td>1.090</td>\n      <td>1.8400</td>\n      <td>4.5300</td>\n      <td>0.160</td>\n      <td>0.3130</td>\n      <td>1.7100</td>\n      <td>5.5600</td>\n    </tr>\n    <tr>\n      <th>2020-01-08</th>\n      <td>2.620</td>\n      <td>6.0700</td>\n      <td>0.0800</td>\n      <td>0.10000</td>\n      <td>3.07</td>\n      <td>3.690</td>\n      <td>0.7330</td>\n      <td>2.030</td>\n      <td>2.1900</td>\n      <td>0.240</td>\n      <td>2.4700</td>\n      <td>3.720</td>\n      <td>0.8000</td>\n      <td>5.110</td>\n      <td>0.200</td>\n      <td>1.2300</td>\n      <td>1.2500</td>\n      <td>1.1100</td>\n      <td>1.9100</td>\n      <td>3.650</td>\n      <td>2.9200</td>\n      <td>4.16</td>\n      <td>1.32</td>\n      <td>1.3100</td>\n      <td>0.6500</td>\n      <td>7.150</td>\n      <td>1.770</td>\n      <td>0.4450</td>\n      <td>1.55</td>\n      <td>6.610</td>\n      <td>2.4900</td>\n      <td>0.605</td>\n      <td>0.7200</td>\n      <td>19.459999</td>\n      <td>4.5200</td>\n      <td>2.4200</td>\n      <td>3.000</td>\n      <td>2.9100</td>\n      <td>14.7500</td>\n      <td>3.240</td>\n      <td>...</td>\n      <td>0.17000</td>\n      <td>4.410</td>\n      <td>0.859</td>\n      <td>6.6000</td>\n      <td>1.150</td>\n      <td>2.310</td>\n      <td>5.5080</td>\n      <td>1.6700</td>\n      <td>0.040</td>\n      <td>1.3600</td>\n      <td>1.2400</td>\n      <td>4.91</td>\n      <td>0.19860</td>\n      <td>4.970</td>\n      <td>0.47040</td>\n      <td>9.8900</td>\n      <td>0.4296</td>\n      <td>2.52000</td>\n      <td>4.950</td>\n      <td>3.810</td>\n      <td>1.720</td>\n      <td>0.7000</td>\n      <td>2.040</td>\n      <td>0.17000</td>\n      <td>0.6100</td>\n      <td>0.25000</td>\n      <td>2.950</td>\n      <td>1.4900</td>\n      <td>2.580</td>\n      <td>6.25</td>\n      <td>0.75</td>\n      <td>1.2600</td>\n      <td>1.580</td>\n      <td>1.070</td>\n      <td>1.5900</td>\n      <td>4.5900</td>\n      <td>0.160</td>\n      <td>0.3200</td>\n      <td>1.6200</td>\n      <td>5.3100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-06-01</th>\n      <td>1.710</td>\n      <td>3.4900</td>\n      <td>0.0636</td>\n      <td>0.07920</td>\n      <td>2.86</td>\n      <td>2.960</td>\n      <td>1.1180</td>\n      <td>1.430</td>\n      <td>0.5071</td>\n      <td>0.365</td>\n      <td>2.5700</td>\n      <td>1.750</td>\n      <td>0.6991</td>\n      <td>5.240</td>\n      <td>0.139</td>\n      <td>0.4800</td>\n      <td>2.0000</td>\n      <td>0.9012</td>\n      <td>1.2555</td>\n      <td>4.315</td>\n      <td>1.6100</td>\n      <td>4.05</td>\n      <td>3.72</td>\n      <td>1.0807</td>\n      <td>2.0899</td>\n      <td>3.635</td>\n      <td>1.790</td>\n      <td>0.3581</td>\n      <td>1.03</td>\n      <td>10.500</td>\n      <td>1.1087</td>\n      <td>1.250</td>\n      <td>1.8208</td>\n      <td>4.570000</td>\n      <td>5.7100</td>\n      <td>2.5800</td>\n      <td>4.020</td>\n      <td>7.2376</td>\n      <td>2.8299</td>\n      <td>3.375</td>\n      <td>...</td>\n      <td>0.19720</td>\n      <td>2.100</td>\n      <td>1.800</td>\n      <td>2.4300</td>\n      <td>1.270</td>\n      <td>1.250</td>\n      <td>6.8800</td>\n      <td>1.6500</td>\n      <td>0.160</td>\n      <td>3.3300</td>\n      <td>2.4400</td>\n      <td>2.42</td>\n      <td>0.06355</td>\n      <td>2.100</td>\n      <td>0.75000</td>\n      <td>2.7700</td>\n      <td>0.3820</td>\n      <td>2.61000</td>\n      <td>3.510</td>\n      <td>5.980</td>\n      <td>3.950</td>\n      <td>2.6000</td>\n      <td>2.400</td>\n      <td>0.11620</td>\n      <td>0.2318</td>\n      <td>0.06670</td>\n      <td>1.570</td>\n      <td>1.9900</td>\n      <td>1.720</td>\n      <td>3.00</td>\n      <td>1.80</td>\n      <td>3.5400</td>\n      <td>1.450</td>\n      <td>4.600</td>\n      <td>2.9300</td>\n      <td>3.0700</td>\n      <td>4.255</td>\n      <td>0.8239</td>\n      <td>0.8025</td>\n      <td>5.0700</td>\n    </tr>\n    <tr>\n      <th>2021-06-02</th>\n      <td>1.745</td>\n      <td>3.5690</td>\n      <td>0.0645</td>\n      <td>0.11490</td>\n      <td>3.02</td>\n      <td>2.910</td>\n      <td>1.1400</td>\n      <td>1.440</td>\n      <td>0.5290</td>\n      <td>0.365</td>\n      <td>2.6100</td>\n      <td>1.755</td>\n      <td>0.6987</td>\n      <td>5.255</td>\n      <td>0.140</td>\n      <td>0.5085</td>\n      <td>2.3200</td>\n      <td>0.9186</td>\n      <td>1.3300</td>\n      <td>4.060</td>\n      <td>1.5300</td>\n      <td>4.11</td>\n      <td>3.66</td>\n      <td>1.0790</td>\n      <td>2.0900</td>\n      <td>3.355</td>\n      <td>1.880</td>\n      <td>0.3568</td>\n      <td>1.20</td>\n      <td>10.220</td>\n      <td>1.1150</td>\n      <td>1.275</td>\n      <td>1.7250</td>\n      <td>4.590000</td>\n      <td>5.5300</td>\n      <td>2.7800</td>\n      <td>3.940</td>\n      <td>7.1100</td>\n      <td>2.9800</td>\n      <td>3.450</td>\n      <td>...</td>\n      <td>0.21700</td>\n      <td>2.125</td>\n      <td>1.855</td>\n      <td>2.4173</td>\n      <td>1.245</td>\n      <td>1.220</td>\n      <td>6.4100</td>\n      <td>1.6079</td>\n      <td>0.168</td>\n      <td>3.4250</td>\n      <td>2.3762</td>\n      <td>2.48</td>\n      <td>0.06230</td>\n      <td>2.190</td>\n      <td>0.76480</td>\n      <td>2.7800</td>\n      <td>0.3820</td>\n      <td>2.60500</td>\n      <td>3.530</td>\n      <td>5.960</td>\n      <td>3.925</td>\n      <td>2.4650</td>\n      <td>2.420</td>\n      <td>0.11630</td>\n      <td>0.2414</td>\n      <td>0.06330</td>\n      <td>1.700</td>\n      <td>2.0100</td>\n      <td>1.700</td>\n      <td>3.22</td>\n      <td>1.82</td>\n      <td>3.5500</td>\n      <td>1.488</td>\n      <td>4.650</td>\n      <td>3.1550</td>\n      <td>3.0400</td>\n      <td>4.145</td>\n      <td>0.8379</td>\n      <td>0.8006</td>\n      <td>5.2800</td>\n    </tr>\n    <tr>\n      <th>2021-06-03</th>\n      <td>1.825</td>\n      <td>3.7000</td>\n      <td>0.0631</td>\n      <td>0.07609</td>\n      <td>2.90</td>\n      <td>2.881</td>\n      <td>1.1400</td>\n      <td>1.445</td>\n      <td>0.5373</td>\n      <td>0.365</td>\n      <td>2.7225</td>\n      <td>1.740</td>\n      <td>1.0100</td>\n      <td>5.140</td>\n      <td>0.130</td>\n      <td>0.5228</td>\n      <td>2.2900</td>\n      <td>0.8824</td>\n      <td>1.3400</td>\n      <td>4.050</td>\n      <td>1.5599</td>\n      <td>4.08</td>\n      <td>3.95</td>\n      <td>1.1350</td>\n      <td>2.0900</td>\n      <td>3.325</td>\n      <td>1.791</td>\n      <td>0.3626</td>\n      <td>1.20</td>\n      <td>10.300</td>\n      <td>1.1381</td>\n      <td>1.300</td>\n      <td>1.7000</td>\n      <td>4.615000</td>\n      <td>5.5850</td>\n      <td>3.0400</td>\n      <td>3.935</td>\n      <td>7.8000</td>\n      <td>3.0959</td>\n      <td>3.330</td>\n      <td>...</td>\n      <td>0.23160</td>\n      <td>2.160</td>\n      <td>1.800</td>\n      <td>2.4400</td>\n      <td>1.225</td>\n      <td>1.250</td>\n      <td>6.6200</td>\n      <td>1.5500</td>\n      <td>0.160</td>\n      <td>3.3336</td>\n      <td>2.8199</td>\n      <td>2.38</td>\n      <td>0.06500</td>\n      <td>2.165</td>\n      <td>0.75200</td>\n      <td>2.7301</td>\n      <td>0.3512</td>\n      <td>2.55000</td>\n      <td>3.542</td>\n      <td>6.095</td>\n      <td>3.985</td>\n      <td>2.3750</td>\n      <td>2.390</td>\n      <td>0.11990</td>\n      <td>0.2526</td>\n      <td>0.05730</td>\n      <td>1.670</td>\n      <td>2.0800</td>\n      <td>1.715</td>\n      <td>3.92</td>\n      <td>1.74</td>\n      <td>3.5242</td>\n      <td>1.660</td>\n      <td>4.645</td>\n      <td>3.1500</td>\n      <td>3.1400</td>\n      <td>4.290</td>\n      <td>1.0050</td>\n      <td>0.8069</td>\n      <td>5.1819</td>\n    </tr>\n    <tr>\n      <th>2021-06-04</th>\n      <td>1.705</td>\n      <td>3.6451</td>\n      <td>0.0620</td>\n      <td>0.08000</td>\n      <td>3.01</td>\n      <td>2.990</td>\n      <td>1.1174</td>\n      <td>1.490</td>\n      <td>0.5503</td>\n      <td>0.360</td>\n      <td>2.6901</td>\n      <td>1.750</td>\n      <td>0.9461</td>\n      <td>5.230</td>\n      <td>0.147</td>\n      <td>0.5147</td>\n      <td>2.2452</td>\n      <td>0.8782</td>\n      <td>1.4400</td>\n      <td>4.035</td>\n      <td>1.5400</td>\n      <td>4.04</td>\n      <td>4.26</td>\n      <td>1.0781</td>\n      <td>2.1118</td>\n      <td>3.405</td>\n      <td>1.800</td>\n      <td>0.3632</td>\n      <td>1.15</td>\n      <td>10.300</td>\n      <td>1.1600</td>\n      <td>1.290</td>\n      <td>1.7550</td>\n      <td>4.485000</td>\n      <td>5.4754</td>\n      <td>3.1401</td>\n      <td>4.220</td>\n      <td>7.7100</td>\n      <td>3.2300</td>\n      <td>3.240</td>\n      <td>...</td>\n      <td>0.23420</td>\n      <td>2.130</td>\n      <td>1.805</td>\n      <td>2.5514</td>\n      <td>1.265</td>\n      <td>1.210</td>\n      <td>6.7171</td>\n      <td>1.5350</td>\n      <td>0.156</td>\n      <td>3.3600</td>\n      <td>2.4400</td>\n      <td>2.34</td>\n      <td>0.06620</td>\n      <td>2.320</td>\n      <td>0.76000</td>\n      <td>2.7450</td>\n      <td>0.3541</td>\n      <td>2.65500</td>\n      <td>3.500</td>\n      <td>6.370</td>\n      <td>4.005</td>\n      <td>2.4024</td>\n      <td>2.465</td>\n      <td>0.11785</td>\n      <td>0.2690</td>\n      <td>0.06615</td>\n      <td>1.690</td>\n      <td>2.3463</td>\n      <td>1.680</td>\n      <td>4.02</td>\n      <td>1.76</td>\n      <td>3.3500</td>\n      <td>1.610</td>\n      <td>4.695</td>\n      <td>3.0098</td>\n      <td>3.0529</td>\n      <td>4.350</td>\n      <td>0.9110</td>\n      <td>0.8187</td>\n      <td>5.1800</td>\n    </tr>\n    <tr>\n      <th>2021-06-07</th>\n      <td>1.740</td>\n      <td>3.6400</td>\n      <td>0.0735</td>\n      <td>0.06650</td>\n      <td>3.27</td>\n      <td>2.970</td>\n      <td>1.1486</td>\n      <td>1.550</td>\n      <td>0.5715</td>\n      <td>0.360</td>\n      <td>2.8200</td>\n      <td>1.760</td>\n      <td>1.0500</td>\n      <td>5.000</td>\n      <td>0.140</td>\n      <td>0.5263</td>\n      <td>2.2000</td>\n      <td>0.9068</td>\n      <td>1.4500</td>\n      <td>4.280</td>\n      <td>1.5400</td>\n      <td>4.16</td>\n      <td>4.53</td>\n      <td>1.1000</td>\n      <td>2.1800</td>\n      <td>3.440</td>\n      <td>1.760</td>\n      <td>0.3670</td>\n      <td>1.14</td>\n      <td>10.290</td>\n      <td>1.2000</td>\n      <td>1.270</td>\n      <td>1.7900</td>\n      <td>4.760000</td>\n      <td>5.6900</td>\n      <td>3.2400</td>\n      <td>4.200</td>\n      <td>7.7400</td>\n      <td>3.0400</td>\n      <td>3.300</td>\n      <td>...</td>\n      <td>0.25945</td>\n      <td>2.170</td>\n      <td>1.960</td>\n      <td>2.6500</td>\n      <td>1.300</td>\n      <td>1.235</td>\n      <td>6.7849</td>\n      <td>1.6200</td>\n      <td>0.157</td>\n      <td>3.4600</td>\n      <td>2.6200</td>\n      <td>3.00</td>\n      <td>0.07250</td>\n      <td>2.330</td>\n      <td>0.75310</td>\n      <td>2.7700</td>\n      <td>0.3533</td>\n      <td>2.65710</td>\n      <td>3.530</td>\n      <td>6.630</td>\n      <td>4.240</td>\n      <td>2.5900</td>\n      <td>2.540</td>\n      <td>0.12000</td>\n      <td>0.2650</td>\n      <td>0.06604</td>\n      <td>1.650</td>\n      <td>2.3200</td>\n      <td>1.740</td>\n      <td>3.75</td>\n      <td>1.76</td>\n      <td>3.5000</td>\n      <td>1.630</td>\n      <td>5.240</td>\n      <td>3.2400</td>\n      <td>3.0000</td>\n      <td>4.250</td>\n      <td>0.9667</td>\n      <td>0.9148</td>\n      <td>5.3100</td>\n    </tr>\n  </tbody>\n</table>\n<p>360 rows × 412 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# load and shape data\n",
    "conn = sqlite3.connect('stockPrediction_06072021.db')\n",
    "\n",
    "symbol_info = conn.execute(f\"SELECT sector_id, industry_id FROM stock WHERE stock_symbol = \\\"{model_settings['symbol']}\\\";\")\n",
    "symbol_info = symbol_info.fetchall()\n",
    "sector_id = symbol_info[0][0]\n",
    "industry_id = symbol_info[0][1]\n",
    "\n",
    "query = f\"SELECT r.stock_symbol, l.price_datetime, l.open_price, l.high_price, l.low_price, l.close_price, l.volume, l.dividends, l.stock_splits FROM eod_price_history l INNER JOIN stock r ON r.stock_id = l.stock_id WHERE r.sector_id = {sector_id} OR r.industry_id = {industry_id};\"\n",
    "\n",
    "symbols = conn.execute('SELECT stock_symbol FROM stock')\n",
    "symbols = symbols.fetchall()\n",
    "symbols = [i[0] for i in symbols]\n",
    "symbols = [i for i in symbols if i not in symbols]\n",
    "\n",
    "df = pd.read_sql(query, conn, index_col=['stock_symbol', 'price_datetime'])\n",
    "df = df.reset_index()\n",
    "\n",
    "df['price_datetime'] = pd.to_datetime(df['price_datetime'], format='%Y-%m-%d')\n",
    "\n",
    "df = df.set_index(['price_datetime', 'stock_symbol']).unstack(['stock_symbol'])\n",
    "\n",
    "df = df.loc[model_settings['start_date']:current_date]  # date range from 2019-01-01 to 2021-05-31\n",
    "\n",
    "close_df = df['close_price'].dropna(thresh=(len(df['close_price'] / 0.2)), axis=1)\n",
    "\n",
    "close_df = close_df.fillna(method='ffill', axis=1)\n",
    "\n",
    "# remove outliers\n",
    "low_outlier = close_df.quantile(.1, axis=1).quantile(.1)\n",
    "high_outlier = close_df.quantile(.9, axis=1).quantile(.9)\n",
    "for column in close_df.columns:\n",
    "    if (close_df[column].median() < low_outlier) or (close_df[column].median() > high_outlier):\n",
    "        close_df = close_df.drop([column], axis=1)\n",
    "close_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sequences function, splits multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find end of patterns\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check to see if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input, output parts of the pattern\n",
    "        # slightly guessing here on how to combine these two examples\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test/train data sets\n",
    "\n",
    "# splitting test/training data\n",
    "data_size = len(close_df)\n",
    "\n",
    "# using a 90/10 train/test split\n",
    "training_data = close_df.iloc[:(int(data_size * model_settings['train_test_ratio']))]\n",
    "test_data = close_df.iloc[(int(data_size * model_settings['train_test_ratio'])):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data sets to see if they're correct\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'for i in range(len(training_data)):\\n    out_seq.append(training_data.iloc[i].sum())\\nout_seq = np.array(out_seq, dtype=np.float)'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#df['sum'] = df.sum(axis=1)\n",
    "\n",
    "# ignore others, working w/ this cell currently\n",
    "\n",
    "arrays = list()\n",
    "out_seq = list()\n",
    "for i in range(len(training_data)):\n",
    "    arrays.append(training_data.iloc[i].to_numpy(dtype=np.float))\n",
    "'''for i in range(len(training_data)):\n",
    "    out_seq.append(training_data.iloc[i].sum())\n",
    "out_seq = np.array(out_seq, dtype=np.float)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "len(arrays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape arrays\n",
    "# in_seq arrays\n",
    "for i in range(len(arrays)):\n",
    "    arrays[i] = arrays[i].reshape((len(arrays[i]), 1))\n",
    "# out_seq = out_seq.reshape((len(out_seq), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays.append(out_seq)\n",
    "dataset = np.hstack((arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may just be able to jump right into using the split_sequence func?\n",
    "X, y = split_sequences(dataset, model_settings['n_steps_in'], model_settings['n_steps_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n(30, 251)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    print(y[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=(model_settings['n_steps_in'], n_features)))\n",
    "model.add(RepeatVector(model_settings['n_steps_out']))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "# model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/400\n",
      "11/11 [==============================] - 4s 220ms/step - loss: nan\n",
      "Epoch 2/400\n",
      "11/11 [==============================] - 3s 228ms/step - loss: nan\n",
      "Epoch 3/400\n",
      "11/11 [==============================] - 2s 220ms/step - loss: nan\n",
      "Epoch 4/400\n",
      "11/11 [==============================] - 3s 230ms/step - loss: nan\n",
      "Epoch 5/400\n",
      "11/11 [==============================] - 2s 227ms/step - loss: nan\n",
      "Epoch 6/400\n",
      "11/11 [==============================] - 2s 225ms/step - loss: nan\n",
      "Epoch 7/400\n",
      "11/11 [==============================] - 2s 226ms/step - loss: nan\n",
      "Epoch 8/400\n",
      "11/11 [==============================] - 2s 224ms/step - loss: nan\n",
      "Epoch 9/400\n",
      " 5/11 [============>.................] - ETA: 1s - loss: nan"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e3916cea3080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=400, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((323, 60, 251), (323, 30, 251))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "len(training_data)"
   ]
  }
 ]
}