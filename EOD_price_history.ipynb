{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd004ac14935f6ed29b3349ee8f41114d2dfa2ba78ce87cf701ad9b7ca15955b787",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock import Stock\n",
    "from stock import Price\n",
    "from stock import get_current_datetime\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the DB, gather stock symbols, add to a list\n",
    "# create an SQLite db connection\n",
    "conn = sqlite3.connect('stockPrediction.db')\n",
    "\n",
    "# collect stock symbols from DB, add to a list\n",
    "dbq = conn.execute('SELECT stock_symbol FROM stock')\n",
    "conn.commit()\n",
    "dbq = dbq.fetchall()\n",
    "# the result from dbq.fetchall() is a list of single-element tuples\n",
    "# the list comprehension below turns it into a list of strings instead\n",
    "db_symbols = [x[0] for x in dbq]\n",
    "\n",
    "# create a dict of stock symbols and their stock_id\n",
    "dbq = conn.execute('SELECT stock_id, stock_symbol FROM stock')\n",
    "conn.commit()\n",
    "dbq = dbq.fetchall()\n",
    "stock_id_dict = dict()  # keys are ticker symbols, vals are the ID #\n",
    "\n",
    "try:\n",
    "    infile = open('gphl_symbol', 'rb')\n",
    "    pickle_symbol = pickle.load(infile)\n",
    "    pickle_symbol_read = False\n",
    "except:\n",
    "    pickle_symbol = None\n",
    "    pickle_symbol_read = True\n",
    "    \n",
    "for x in dbq:\n",
    "    stock_id_dict[x[1]] = x[0]\n",
    "\n",
    "# try:\n",
    "    # infile = open('gphl_symbol', 'rb')\n",
    "    # pickle_symbol = pickle.load(infile)\n",
    "    # pickle_symbol_read = False\n",
    "# except:\n",
    "    # pickle_symbol = None\n",
    "    # pickle_symbol_read = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x15cafe42180>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# this bit adds the EOD price history table to the db if it does not already exist.\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS eod_price_history (\n",
    "    price_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n",
    "    stock_id INTEGER NOT NULL,\n",
    "    price_datetime TEXT NOT NULL,\n",
    "    open_price REAL NOT NULL,\n",
    "    high_price REAL NOT NULL,\n",
    "    low_price REAL NOT NULL,\n",
    "    close_price REAL NOT NULL,\n",
    "    volume INTEGER NOT NULL,\n",
    "    dividends REAL,\n",
    "    stock_splits TEXT,\n",
    "    datetime_added TEXT NOT NULL,\n",
    "    FOREIGN KEY (stock_id)\n",
    "        REFERENCES stock (stock_id)\n",
    "        ON UPDATE CASCADE\n",
    "        ON DELETE CASCADE);''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_history(symbol, conn, period='15min', pickle_symbol_read=True):\n",
    "    '''This function performs API calls using the yfinance module. It takes as arguments a symbol as a string, an sqllite3 connection, and a period, defaulting to 15min, but also allowing for max history w/ a single day interval.'''\n",
    "\n",
    "\n",
    "    # first, check to see if we have a last symbol stored in a pickle\n",
    "    # if not, we return None on this function (ideally, iterating until\n",
    "    # we find the symbol we're looking for)    \n",
    "    if pickle_symbol_read is False:\n",
    "        if symbol == pickle_symbol:\n",
    "            pickle_symbol_read = True\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    # collect price history data that already exists in the DB to avoid redundant data\n",
    "    # determine if 15min or eod\n",
    "    if period == '15min':\n",
    "        data_in_db = conn.execute(f'SELECT price_datetime FROM eod_price_history WHERE stock_id = {stock_id_dict[symbol]}')\n",
    "        conn.commit()\n",
    "        current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        sixty_days_ago = (datetime.datetime.now() - datetime.timedelta(days=59)).strftime(\"%Y-%m-%d\")\n",
    "    elif period == 'eod':\n",
    "        data_in_db = conn.execute(f'SELECT price_datetime FROM eod_price_history WHERE stock_id = {stock_id_dict[symbol]}')\n",
    "    else:\n",
    "        raise TypeError(\"Period is either invalid or not included in this function.\")\n",
    "    data_in_db = data_in_db.fetchall()\n",
    "    # compile a list of prev. price_datetime values\n",
    "    prev_datetimes = [x[0] for x in data_in_db]\n",
    "\n",
    "    # API call\n",
    "    # 15min. intraday\n",
    "    if period == '15min':\n",
    "        try:\n",
    "            print('Performing 15min API call')\n",
    "            data = yf.Ticker(symbol)\n",
    "            data = data.history(\n",
    "                start = sixty_days_ago,\n",
    "                end = current_date,\n",
    "                interval = '15m',\n",
    "                auto_adjust = True\n",
    "            )\n",
    "        except:\n",
    "            print(f'Error processing symbol {symbol}. Skipping to next symbol')\n",
    "            return\n",
    "\n",
    "    # EOD\n",
    "    elif period == 'eod':\n",
    "        try:\n",
    "            print('Performing EOD API call')\n",
    "            data = yf.Ticker(symbol)\n",
    "            data = data.history(\n",
    "                period = 'max',\n",
    "                interval = '1d',\n",
    "                auto_adjust = True,\n",
    "                )\n",
    "        except:\n",
    "            print(f'Error processing symbol {symbol}. Skipping to next symbol')\n",
    "            return\n",
    "    if len(data) == 0:\n",
    "        print(f\"No price history available for {symbol}, skipping to next.\")\n",
    "        time.sleep(5)   # help not get us banned from yf\n",
    "        return\n",
    "\n",
    "    # add columns for datetime retrived and stock_ID\n",
    "    data['datetime_added'] = get_current_datetime()\n",
    "    data['stock_id'] = stock_id_dict[symbol]\n",
    "\n",
    "    # turns the datetime index to a column, so it's actually useful for us\n",
    "    data.reset_index(level=0, inplace=True)\n",
    "\n",
    "    # rename to match our db\n",
    "    data = data.rename(columns={\n",
    "        'Datetime': 'price_datetime',\n",
    "        'Open': 'open_price', \n",
    "        'High': 'high_price', \n",
    "        'Low': 'low_price',\n",
    "        'Close': 'close_price',\n",
    "        'Volume': 'volume',\n",
    "        'Dividends': 'dividends',\n",
    "        'Stock Splits': 'stock_splits'\n",
    "    })\n",
    "\n",
    "    # convert datetime values to string\n",
    "    if period == '15min':\n",
    "        data['price_datetime'] = data['price_datetime'].apply(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    elif period == 'eod':\n",
    "        data['price_datetime'] = data['price_datetime'].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    # fill in np.nan's\n",
    "    impute_columns = []\n",
    "    imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "    imputed_data = imputer.fit_transform(data[['open_price', 'high_price', 'low_price', 'close_price', 'volume', 'dividends']])\n",
    "    clean_data = pd.DataFrame(imputed_data, columns=['open_price', 'high_price', 'low_price', 'close_price', 'volume', 'dividends'])\n",
    "\n",
    "    # copy the cleaned data into our dataframe\n",
    "    data['open_price'] = clean_data['open_price']\n",
    "    data['high_price'] = clean_data['high_price']\n",
    "    data['low_price'] = clean_data['low_price']\n",
    "    data['close_price'] = clean_data['close_price']\n",
    "    data['volume'] = clean_data['volume']\n",
    "    data['dividends'] = clean_data['dividends']\n",
    "\n",
    "    # variables to keep track of redundant data, new data when running this code\n",
    "    new_data = 0\n",
    "    redundant_data = 0\n",
    "\n",
    "    # loop thru the rows, checking to see if we would have duplicate price_datetime values\n",
    "    # if we do, then remove the row\n",
    "    for row in data.itertuples():\n",
    "        \n",
    "        if prev_datetimes.count(row[1]) > 0:\n",
    "            redundant_data += 1\n",
    "            data = data.drop(row.Index)\n",
    "            redundant_data += 1\n",
    "        else:\n",
    "            new_data += 1\n",
    "\n",
    "    # pickle, for restarting the loop if it crashes\n",
    "    outfile = open('gphl_symbol', 'wb')\n",
    "    pickle.dump(symbol,outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    # execute the query\n",
    "    if new_data > 0:\n",
    "        data.to_sql('price_history', conn, if_exists='append', index=False)\n",
    "        conn.commit()\n",
    "\n",
    "    print(symbol, \" price history added to database.\")\n",
    "    print(new_data, \" new entries added.\")\n",
    "    print(redundant_data, \" redundant entries, not added.\")\n",
    "    print('Data added', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    # outfile.open()\n",
    "\n",
    "    # delay to help us not get banned from yf\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing 15min API call\n",
      "CLEU  price history added to database.\n",
      "1019  new entries added.\n",
      "0  redundant entries, not added.\n",
      "Data added 2021-05-18 21:55:12\n",
      "Performing EOD API call\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'price_datetime'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1ab3d1095c6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msymbol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdb_symbols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mget_price_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'15min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_symbol_read\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_symbol_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mget_price_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'eod'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_symbol_read\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_symbol_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-cec7db430874>\u001b[0m in \u001b[0;36mget_price_history\u001b[1;34m(symbol, conn, period, pickle_symbol_read)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price_datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price_datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mperiod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'eod'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price_datetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price_datetime'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# fill in np.nan's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_datetime'"
     ]
    }
   ],
   "source": [
    "for symbol in db_symbols:\n",
    "    get_price_history(symbol, conn, period='15min', pickle_symbol_read=pickle_symbol_read)\n",
    "    get_price_history(symbol, conn, period='eod', pickle_symbol_read=pickle_symbol_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Open    High       Low   Close  Volume  Dividends  Stock Splits\n",
       "Date                                                                         \n",
       "2004-12-22  424.00  424.00  424.0000  424.00       0          0           0.0\n",
       "2004-12-23  424.00  424.00  424.0000  424.00       0          0           0.0\n",
       "2004-12-27  424.00  424.00  424.0000  424.00       0          0           0.0\n",
       "2004-12-28  325.00  400.00  325.0000  330.00      15          0           0.0\n",
       "2004-12-29  375.00  390.00  340.0000  340.00      26          0           0.0\n",
       "...            ...     ...       ...     ...     ...        ...           ...\n",
       "2021-05-12    7.89    8.15    7.5300    7.73   38400          0           0.0\n",
       "2021-05-13    7.66    8.19    7.5500    7.99   97600          0           0.0\n",
       "2021-05-14    8.03    8.50    7.6000    8.30   97000          0           0.0\n",
       "2021-05-17    8.48    8.82    7.8000    8.64  247900          0           0.0\n",
       "2021-05-18    8.71    8.97    8.4001    8.48   79582          0           0.0\n",
       "\n",
       "[4129 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Dividends</th>\n      <th>Stock Splits</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2004-12-22</th>\n      <td>424.00</td>\n      <td>424.00</td>\n      <td>424.0000</td>\n      <td>424.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2004-12-23</th>\n      <td>424.00</td>\n      <td>424.00</td>\n      <td>424.0000</td>\n      <td>424.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2004-12-27</th>\n      <td>424.00</td>\n      <td>424.00</td>\n      <td>424.0000</td>\n      <td>424.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2004-12-28</th>\n      <td>325.00</td>\n      <td>400.00</td>\n      <td>325.0000</td>\n      <td>330.00</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2004-12-29</th>\n      <td>375.00</td>\n      <td>390.00</td>\n      <td>340.0000</td>\n      <td>340.00</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-05-12</th>\n      <td>7.89</td>\n      <td>8.15</td>\n      <td>7.5300</td>\n      <td>7.73</td>\n      <td>38400</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-05-13</th>\n      <td>7.66</td>\n      <td>8.19</td>\n      <td>7.5500</td>\n      <td>7.99</td>\n      <td>97600</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-05-14</th>\n      <td>8.03</td>\n      <td>8.50</td>\n      <td>7.6000</td>\n      <td>8.30</td>\n      <td>97000</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-05-17</th>\n      <td>8.48</td>\n      <td>8.82</td>\n      <td>7.8000</td>\n      <td>8.64</td>\n      <td>247900</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2021-05-18</th>\n      <td>8.71</td>\n      <td>8.97</td>\n      <td>8.4001</td>\n      <td>8.48</td>\n      <td>79582</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4129 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data = yf.Ticker('CREG')\n",
    "data = data.history(period='max', interval='1d', auto_adjust=True)\n",
    "data"
   ]
  }
 ]
}